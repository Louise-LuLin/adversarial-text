<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Adversarial Texts with Gradient Methods</title><meta name="generator" content="Org mode"><meta name="author" content="Zhitao Gong"><link rel="stylesheet" href="http://gongzhitaao.org/orgcss/org.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script></head><body><div id="content"><header><h1 class="title">Adversarial Texts with Gradient Methods</h1></header><nav id="table-of-contents"><h2>Table of Contents</h2><div id="text-table-of-contents"><ul><li><a href="#orge60e9b5">1. Introduction</a></li><li><a href="#sec:result">2. Result</a><ul><li><a href="#subsec:fgsm">2.1. Fast Gradient Sign Method (FGSM)</a></li><li><a href="#subsec:fgvm">2.2. Fast Gradient Value Method (FGVM)</a></li><li><a href="#subsec:deepfool">2.3. DeepFool</a></li></ul></li></ul></div></nav><div id="outline-container-orge60e9b5" class="outline-2"><h2 id="orge60e9b5"><span class="section-number-2">1</span> Introduction</h2><div class="outline-text-2" id="text-1"><p>It has been shown in [<a href="#szegedy2013-intriguing">5</a>] that we can apply very subtle noise to images to trick deep learning into wrong prediction with very high confident. One example in shown in Figure <a href="#org704f596">1</a>. A set of adversarial images via different attacking algorithms are generated from a random image from MNIST dataset. The upper image in <i>Clean</i> column is the original clean image. The upper images in the following columns are adversarial images generated by the corresponding attacking algorithm, based on the first clean image, respectively. The lower image in each column is the differece between the adversarial image and the clean image, illustrated in heatmap. Below each column is the label predicted by the target model, along with probability in parenthesis. The algorithms demonstrated are FGSM [<a href="#goodfellow2014-explaining">1</a>], FGVM [<a href="#miyato2015-distributional">2</a>], JSMA [<a href="#papernot2015-limitations">4</a>] and DeepFool [<a href="#moosavi-dezfooli2015-deepfool">3</a>]. These are all gradient attacking methods.</p><figure id="org704f596"><img src="img/imgdemo.png" alt="imgdemo.png"><figcaption><span class="figure-number">Figure 1: </span>Adversarial examples created on MNIST</figcaption></figure></div></div><div id="outline-container-orgc196d2b" class="outline-2"><h2 id="sec:result"><span class="section-number-2">2</span> Result</h2><div class="outline-text-2" id="text-sec:result"><p>Due to the size of the dataset, we only show 100 samples for each parameter setting on the website. The rest samples could be downloaded. Note that some tokens in the clean dataset are different from the original piece of text, since these texts are also reconstructed by approximate nearest neighbor search for convenience. These does not affect the embedded vectors.</p></div><div id="outline-container-org14ec0bb" class="outline-3"><h3 id="subsec:fgsm"><span class="section-number-3">2.1</span> Fast Gradient Sign Method (FGSM)</h3><div class="outline-text-3" id="text-subsec:fgsm"><p>This was proposed in [<a href="#goodfellow2014-explaining">1</a>]. The adversarial noise is computed as \(z = \epsilon \text{sign}\nabla L\).</p><table id="org5603f76"><caption class="t-above"><span class="table-number">Table 1:</span> Adversarial text via FGSM</caption><colgroup><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"></colgroup><thead><tr><th scope="col" class="org-left">&epsilon;</th><th scope="col" class="org-left">0.40</th><th scope="col" class="org-left">0.35</th><th scope="col" class="org-left">0.30</th><th scope="col" class="org-left">0.25</th></tr></thead><tbody><tr><td class="org-left">IMDB</td><td class="org-left"><a href="result/imdb_fgsm_eps0.40.html">0.1213 / 0.1334</a></td><td class="org-left"><a href="result/imdb_fgsm_eps0.35.html">0.1213 / 0.1990</a></td><td class="org-left"><a href="result/imdb_fgsm_eps0.30.html">0.1213 / 0.4074</a></td><td class="org-left"><a href="result/imdb_fgsm_eps0.25.html">0.1213 / 0.6770</a></td></tr><tr><td class="org-left">Reuters-2</td><td class="org-left"><a href="result/reuters2_fgsm_eps0.40.html">0.0146 / 0.6495</a></td><td class="org-left"><a href="result/reuters2_fgsm_eps0.35.html">0.0146 / 0.7928</a></td><td class="org-left"><a href="result/reuters2_fgsm_eps0.30.html">0.0146 / 0.9110</a></td><td class="org-left"><a href="result/reuters2_fgsm_eps0.25.html">0.0146 / 0.9680</a></td></tr><tr><td class="org-left">Reuters-5</td><td class="org-left"><a href="result/reuters5_fgsm_eps0.40.html">0.1128 / 0.5880</a></td><td class="org-left"><a href="result/reuters5_fgsm_eps0.35.html">0.1128 / 0.7162</a></td><td class="org-left"><a href="result/reuters5_fgsm_eps0.30.html">0.1128 / 0.7949</a></td><td class="org-left"><a href="result/reuters5_fgsm_eps0.25.html">0.1128 / 0.8462</a></td></tr></tbody></table></div></div><div id="outline-container-org1b410e9" class="outline-3"><h3 id="subsec:fgvm"><span class="section-number-3">2.2</span> Fast Gradient Value Method (FGVM)</h3><div class="outline-text-3" id="text-subsec:fgvm"><p>This is a variant of FGSM, instead of gradients, FGVM uses the gradients directly. The noise is \(z = \epsilon\frac{\nabla L}{\|\nabla L\|_2}\).</p><table id="org5b52902"><caption class="t-above"><span class="table-number">Table 2:</span> Adversarial text via FGVM</caption><colgroup><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"></colgroup><thead><tr><th scope="col" class="org-left">&epsilon;</th><th scope="col" class="org-left">15</th><th scope="col" class="org-left">30</th><th scope="col" class="org-left">50</th><th scope="col" class="org-left">100</th></tr></thead><tbody><tr><td class="org-left">IMDB</td><td class="org-left"><a href="result/imdb_fgvm_eps15.html">0.6888 / 0.8538</a></td><td class="org-left"><a href="result/imdb_fgvm_eps30.html">0.6549 / 0.8354</a></td><td class="org-left"><a href="result/imdb_fgvm_eps50.html">0.6277 / 0.8207</a></td><td class="org-left"><a href="result/imdb_fgvm_eps100.html">0.5925 / 0.7964</a></td></tr><tr><td class="org-left">Reuters-2</td><td class="org-left"><a href="result/reuters2_fgvm_eps15.html">0.7747 / 0.7990</a></td><td class="org-left"><a href="result/reuters2_fgvm_eps30.html">0.7337 / 0.7538</a></td><td class="org-left"><a href="result/reuters2_fgvm_eps50.html">0.6975 / 0.7156</a></td><td class="org-left"><a href="result/reuters2_fgvm_eps100.html">0.6349 / 0.6523</a></td></tr><tr><td class="org-left">Reuters-5</td><td class="org-left"><a href="result/reuters5_fgvm_eps15.html">0.5915 / 0.7983</a></td><td class="org-left"><a href="result/reuters5_fgvm_eps30.html">0.5368 / 0.6872</a></td><td class="org-left"><a href="result/reuters5_fgvm_eps50.html">0.4786 / 0.6085</a></td><td class="org-left"><a href="result/reuters5_fgvm_eps100.html">0.4000 / 0.5111</a></td></tr></tbody></table></div></div><div id="outline-container-orge47f7ef" class="outline-3"><h3 id="subsec:deepfool"><span class="section-number-3">2.3</span> DeepFool</h3><div class="outline-text-3" id="text-subsec:deepfool"><p>This method is proposed in [<a href="#moosavi-dezfooli2015-deepfool">3</a>]. DeepFool iteratively finds the optimal direction in which we need to <i>travel</i> the minimum distance to cross the decision boundary of the target model. Although in non-linear cases, this optimality is not guaranteed, DeepFool works well in practice, and usually generates very subtle noise. In many of the examples, DeepFool alters the label of the text piece by replace only one word.</p><table id="orgd5d6268"><caption class="t-above"><span class="table-number">Table 3:</span> Adversarial text via DeepFool</caption><colgroup><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"><col class="org-left"></colgroup><thead><tr><th scope="col" class="org-left">&epsilon;</th><th scope="col" class="org-left">20</th><th scope="col" class="org-left">30</th><th scope="col" class="org-left">40</th><th scope="col" class="org-left">50</th></tr></thead><tbody><tr><td class="org-left">IMDB</td><td class="org-left"><a href="result/imdb_deepfool_eps20.html">0.5569 / 0.8298</a></td><td class="org-left"><a href="result/imdb_deepfool_eps30.html">0.5508 / 0.7225</a></td><td class="org-left"><a href="result/imdb_deepfool_eps40.html">0.5472 / 0.6678</a></td><td class="org-left"><a href="result/imdb_deepfool_eps50.html">0.5453 / 0.6416</a></td></tr><tr><td class="org-left">Reuters-2</td><td class="org-left"><a href="result/reuters2_deepfool_eps20.html">0.4416 / 0.6766</a></td><td class="org-left"><a href="result/reuters2_deepfool_eps30.html">0.4416 / 0.5236</a></td><td class="org-left"><a href="result/reuters2_deepfool_eps40.html">0.4416 / 0.4910</a></td><td class="org-left"><a href="result/reuters2_deepfool_eps50.html">0.4416 / 0.4715</a></td></tr><tr><td class="org-left">Reuters-5</td><td class="org-left"><a href="result/reuters5_deepfool_eps20.html">0.1163 / 0.4034</a></td><td class="org-left"><a href="result/reuters5_deepfool_eps30.html">0.1162 / 0.2222</a></td><td class="org-left"><a href="result/reuters5_deepfool_eps40.html">0.1162 / 0.1641</a></td><td class="org-left"><a href="result/reuters5_deepfool_eps50.html">0.1162 / 0.1402</a></td></tr></tbody></table></div></div></div><div id="bibliography"><h2>References</h2><table><tr valign="top"><td align="right" class="bibtexnumber">[<a name="goodfellow2014-explaining">1</a>]</td><td class="bibtexitem">I.&nbsp;J. Goodfellow, J.&nbsp;Shlens, and C.&nbsp;Szegedy. Explaining and Harnessing Adversarial Examples. <em>ArXiv e-prints</em>, December 2014. [&nbsp;<a href="nn_bib.html#goodfellow2014-explaining">bib</a>&nbsp;| <a href="http://arxiv.org/abs/1412.6572">arXiv</a>&nbsp;]</td></tr><tr valign="top"><td align="right" class="bibtexnumber">[<a name="miyato2015-distributional">2</a>]</td><td class="bibtexitem">Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, and Shin Ishii. Distributional smoothing with virtual adversarial training. <em>stat</em>, 1050:25, 2015. [&nbsp;<a href="nn_bib.html#miyato2015-distributional">bib</a>&nbsp;]</td></tr><tr valign="top"><td align="right" class="bibtexnumber">[<a name="moosavi-dezfooli2015-deepfool">3</a>]</td><td class="bibtexitem">Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. Deepfool: a simple and accurate method to fool deep neural networks. <em>CoRR</em>, abs/1511.04599, 2015. [&nbsp;<a href="nn_bib.html#moosavi-dezfooli2015-deepfool">bib</a>&nbsp;| <a href="http://arxiv.org/abs/1511.04599">arXiv</a>&nbsp;| <a href="http://arxiv.org/abs/1511.04599">http</a>&nbsp;]</td></tr><tr valign="top"><td align="right" class="bibtexnumber">[<a name="papernot2015-limitations">4</a>]</td><td class="bibtexitem">Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z.&nbsp;Berkay Celik, and Ananthram Swami. The limitations of deep learning in adversarial settings. <em>CoRR</em>, abs/1511.07528, 2015. [&nbsp;<a href="nn_bib.html#papernot2015-limitations">bib</a>&nbsp;| <a href="http://arxiv.org/abs/1511.07528">http</a>&nbsp;]</td></tr><tr valign="top"><td align="right" class="bibtexnumber">[<a name="szegedy2013-intriguing">5</a>]</td><td class="bibtexitem">Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian&nbsp;J. Goodfellow, and Rob Fergus. Intriguing properties of neural networks. <em>CoRR</em>, abs/1312.6199, 2013. [&nbsp;<a href="nn_bib.html#szegedy2013-intriguing">bib</a>&nbsp;| <a href="http://arxiv.org/abs/1312.6199">http</a>&nbsp;]</td></tr></table></div></div><div id="postamble" class="status"><a class="author" href="http://gongzhitaao.org">Zhitao Gong</a> / <span class="date">2018-01-04 Thu 19:50</span><span class="creator"><a href="https://www.gnu.org/software/emacs/">Emacs</a> 25.2.2 (<a href="http://orgmode.org">Org</a> mode 9.1.6)</span></div></body></html>